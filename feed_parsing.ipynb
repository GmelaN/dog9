{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof-of-Concept notepad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from collections import namedtuple\n",
    "import re\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "Article = namedtuple(\"Article\", [\"title\", \"content\", \"url\", \"pub_time\", \"section\", \"press\", \"image\"])\n",
    "SummerizedArticle = namedtuple(\"SummerizedArticle\", [\"title\", \"content\", \"url\", \"pub_time\", \"section\", \"press\", \"problem\", \"issue\", \"keyword\", \"tag\"])\n",
    "\n",
    "Journal = namedtuple(\"Journal\", [\"journalNm\", \"journalId\"])\n",
    "\n",
    "Tag = namedtuple(\"Tag\", [\"tagId\", \"tagName\"])\n",
    "\n",
    "model = None\n",
    "tokenizer = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class LLM:\n",
    "    MODEL_ID = \"MLP-KTLim/llama-3-Korean-Bllossom-8B-gguf-Q4_K_M\"\n",
    "    MODEL_PATH = \"/home/gpp/src/model/llama3-korean-bllossom-8b/llama-3-Korean-Bllossom-8B-Q4_K_M.gguf\"\n",
    "\n",
    "    model: Llama | None = None\n",
    "    tokenizer: AutoTokenizer | None = None\n",
    "\n",
    "    prompt: str = \"\"\n",
    "\n",
    "    def __init__(self, verbose: bool=False, temperature: float=0.3, top_p: float=0.9, max_tokens: int=2048):\n",
    "        if LLM.model is None:\n",
    "            LLM.model = Llama(\n",
    "                model_path=LLM.MODEL_PATH,\n",
    "                n_ctx=8192,\n",
    "                n_gpu_layers=-1,\n",
    "                verbose=verbose\n",
    "            )\n",
    "        \n",
    "        if LLM.tokenizer is None:\n",
    "            LLM.tokenizer = AutoTokenizer.from_pretrained(LLM.MODEL_ID)\n",
    "\n",
    "        self.temperature = temperature\n",
    "        self.top_p = top_p\n",
    "        self.max_tokens = max_tokens\n",
    "        self.temperature = temperature\n",
    "        self.prompt: str = \"\"\n",
    "    \n",
    "    def __del__(self):\n",
    "        del LLM.model\n",
    "        del LLM.tokenizer\n",
    "\n",
    "        LLM.model = None\n",
    "        LLM.tokenizer = None\n",
    "\n",
    "    def set_prompt(self, prompt: str):\n",
    "        self.prompt = prompt\n",
    "        return\n",
    "    \n",
    "    def generate(self, instruction: str):\n",
    "        if len(self.prompt) == 0:\n",
    "            raise ValueError(\"prompt is not set.\")\n",
    "        \n",
    "        if len(instruction) == 0:\n",
    "            raise ValueError(\"instruction is not set.\")\n",
    "        \n",
    "        generation_kwargs = {\n",
    "            \"max_tokens\":self.max_tokens,\n",
    "            \"stop\":[\"<|eot_id|>\"],\n",
    "            \"top_p\":self.top_p,\n",
    "            \"temperature\":self.temperature,\n",
    "        }\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": f\"{self.prompt}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{instruction}\"}\n",
    "        ]\n",
    "\n",
    "        p = LLM.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        response = LLM.model(p, **generation_kwargs)\n",
    "        return response[\"choices\"][0][\"text\"]\n",
    "\n",
    "llm: LLM = LLM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApiWrapper:\n",
    "    TOKEN: str = \"\"\n",
    "    URL: str = \"\"\n",
    "    AUTH: dict = {}\n",
    "    TAG_TABLE: dict = {}\n",
    "\n",
    "    def __init__(self, url=URL_):\n",
    "        ApiWrapper.URL = url\n",
    "        ApiWrapper.AUTH = AUTH\n",
    "\n",
    "        if AUTH:\n",
    "            self.login()\n",
    "            self.refresh_tag_table()\n",
    "\n",
    "\n",
    "    def register(self):\n",
    "        response = self.send(\"/auth/eula\", method=\"GET\", auth=False)\n",
    "        eulas = [eula[\"eulaId\"] for eula in response.json()[\"data\"]]\n",
    "\n",
    "        payload = {\n",
    "            \"userId\": ApiWrapper.AUTH[\"userId\"],\n",
    "            \"password\": ApiWrapper.AUTH[\"password\"],\n",
    "            \"userNm\": \"LLM_TEST\",\n",
    "            \"gender\": \"MALE\",\n",
    "            \"birthDate\": \"2001-08-16\",\n",
    "            \"interestTagIds\": [\n",
    "                \"test_tag\"\n",
    "            ],\n",
    "            \"agreedEulaIds\": eulas\n",
    "        }\n",
    "\n",
    "        response = self.send(\"/auth/sign-up\", method=\"POST\", auth=False, data=payload)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return self.login()\n",
    "        \n",
    "        return response.status_code\n",
    "\n",
    "\n",
    "    def login(self):\n",
    "        response = self.send(\"/auth/token\", method=\"POST\", auth=False, data=ApiWrapper.AUTH)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            ApiWrapper.TOKEN = response.json()[\"data\"][0][\"accessToken\"]\n",
    "\n",
    "        return ApiWrapper.TOKEN\n",
    "\n",
    "\n",
    "    def upload_journal(self, journal_name: str) -> int:\n",
    "        uploaded_journals = self.get_uploaded_journals()\n",
    "\n",
    "        if self.get_journal_id(uploaded_journals, journal_name) is None:\n",
    "            journal_id =  \"%04d\" % (len(uploaded_journals) + 1)\n",
    "            response = self.send(\"/journal\", method=\"POST\", auth=True, data={\"journalId\": journal_id, \"journalNm\": journal_name})\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                raise RuntimeError(\"failed to upload journal: %s\" % response.text)\n",
    "\n",
    "        return journal_id\n",
    "\n",
    "\n",
    "    def get_uploaded_journals(self) -> list[Journal]:\n",
    "        response = self.send(\"/journal\", method=\"GET\", auth=True)\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(\"unable to fetch uploaded journal: %s\" % response.text)\n",
    "\n",
    "\n",
    "        journals: list[Journal] = []\n",
    "        for journal in response.json():\n",
    "            journals.append(Journal(journalNm=journal[\"journalNm\"], journalId=journal[\"journalId\"]))\n",
    "\n",
    "        return journals\n",
    "\n",
    "\n",
    "    def get_uploaded_tags(self):\n",
    "        response = self.send(\"/tag\", method=\"GET\", auth=True)\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(\"unable to fetch uploaded tag(s): %s\" % response.text)\n",
    "\n",
    "        tags: list[Tag] = []\n",
    "        for tag in response.json():\n",
    "            tags.append(Tag(tagId=tag[\"tagId\"], tagName=tag[\"tagName\"]))\n",
    "        \n",
    "        return tags\n",
    "    \n",
    "\n",
    "    def refresh_tag_table(self):\n",
    "        ApiWrapper.TAG_TABLE = {}\n",
    "        tags = self.get_uploaded_tags()\n",
    "\n",
    "        for tag in tags:\n",
    "            ApiWrapper.TAG_TABLE[tag.tagId] = tag.tagName\n",
    "\n",
    "        return ApiWrapper.TAG_TABLE\n",
    "    \n",
    "\n",
    "    def upload_tag(self, tag_name: str, tag_id: str):\n",
    "        self.refresh_tag_table()\n",
    "        \n",
    "        for tag in ApiWrapper.TAG_TABLE.keys():\n",
    "            if tag_name == ApiWrapper.TAG_TABLE[tag]:\n",
    "                return tag\n",
    "\n",
    "        response = self.send(\"/tag\", method=\"POST\", auth=True, data={\"tagName\": tag_name, \"tagId\": tag_id})\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(\"failed to upload tag: %s\" % response.text)\n",
    "\n",
    "        ApiWrapper.TAG_TABLE[tag_id] = tag_name\n",
    "\n",
    "        return tag_id\n",
    "\n",
    "\n",
    "    def upload_news(self, news: list[Article], tag_name: str):\n",
    "        for n in news:\n",
    "            journal_id = self.upload_journal(n.press)\n",
    "            tag_id = self.upload_tag(n.section, n.section)\n",
    "\n",
    "            data = {\n",
    "                \"title\": n.title,\n",
    "                \"link\": n.url,\n",
    "                \"journalId\": journal_id,\n",
    "                \"publicationDate\": n.pub_time,\n",
    "                \"tagIds\": [tag_id]\n",
    "            }\n",
    "\n",
    "            response = self.send(\"/news\", auth=True, data=data)\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                raise RuntimeError(\"failed to upload news: %s\" % response.text)\n",
    "\n",
    "\n",
    "    def send(self, endpoint: str, method: Literal[\"GET\", \"POST\"]=\"GET\", auth: bool=True, data: dict={}) -> requests.Response:\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "\n",
    "        url = ApiWrapper.URL + endpoint\n",
    "\n",
    "        if auth:\n",
    "            if len(ApiWrapper.TOKEN) == 0:\n",
    "                self.login()\n",
    "\n",
    "            headers[\"Authorization\"] = \"Bearer \" + ApiWrapper.TOKEN\n",
    "\n",
    "        if method == \"POST\":\n",
    "            response = requests.post(url=url, headers=headers, json=data)\n",
    "            \n",
    "        # elif method == \"GET\":\n",
    "\n",
    "        else: # default: GET\n",
    "            response = requests.get(url=url, headers=headers, json=data)\n",
    "            \n",
    "        return response\n",
    "\n",
    "\n",
    "    def get_journal_name(self, journals: list[Journal], id: int) -> Journal:\n",
    "        for journal in journals:\n",
    "            if journal.journalId == id:\n",
    "                return journal\n",
    "            \n",
    "        return None\n",
    "\n",
    "\n",
    "    def get_journal_id(self, journals: list[Journal], name: str) -> Journal:\n",
    "        for journal in journals:\n",
    "            if journal.journalNm == name:\n",
    "                return journal\n",
    "\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fetch news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOW: str = datetime.now(tz=timezone(timedelta(hours=9))).strftime(\"%Y%m%d%H%M\")\n",
    "DEFAULT_IMAGE_URL: str = \"https://i.namu.wiki/i/aemZBGJQLVu6ePeapyhYqE6OCJQId6CbI0WnQ6CqzTUJpHCO4EzLhRR4HZqy01pjxIA4AywnLqm_Ysw5A-9TJsbqpOKjEnK6rA5VjJf0phRNIhSIu7RINe2JsOzfiZ0pD5ySVhrKAixdSUX0a4xuEQ.webp\"\n",
    "\n",
    "header: dict = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36\"}\n",
    "\n",
    "sections = {\n",
    "    # \"정치\" : 100,\n",
    "    # \"경제\": 101,\n",
    "    # \"사회\": 102,\n",
    "    \"생활\": 103,\n",
    "    # \"세계\": 104,\n",
    "    # \"과학\": 105 \n",
    "}\n",
    "\n",
    "news = {\n",
    "    section : []\n",
    "    for section in sections.keys()\n",
    "}\n",
    "\n",
    "for section in sections.keys():\n",
    "    articles: list[Article] = []\n",
    "\n",
    "    for page in range(1):\n",
    "        url = f\"https://news.naver.com/section/template/SECTION_ARTICLE_LIST?sid={sections[section]}&sid2=&cluid=&pageNo={page}&date=&next={NOW}\"\n",
    "        response = requests.get(url, headers=header)\n",
    "        bs = BeautifulSoup(json.loads(response.text)[\"renderedComponent\"][\"SECTION_ARTICLE_LIST\"], 'html')\n",
    "        sleep(0.5 + randint(0, 100) * 0.1)\n",
    "\n",
    "        for element in bs.findAll(\"li\"):\n",
    "            url: str = element.select(\"a\")[0][\"href\"].strip()\n",
    "            response = requests.get(url, headers=header)\n",
    "\n",
    "            pub_time: str = element.select(\".sa_text_datetime\")[0].text.strip()\n",
    "\n",
    "            if pub_time[-1:] == \"전\": # \"xx분전\"\n",
    "                numbers = int(\"\".join(re.findall(r'\\d+', pub_time)))\n",
    "\n",
    "                timestamp_utc = datetime.now(timezone.utc) - timedelta(minutes=numbers)\n",
    "                kst_time = timestamp_utc.astimezone(timezone(timedelta(hours=9)))\n",
    "                pub_time = kst_time.isoformat().split(\"+\")[0]\n",
    "\n",
    "            content_bs = BeautifulSoup(response.text).select(\"#newsct_article\")[0]\n",
    "\n",
    "            articles.append(\n",
    "                Article(\n",
    "                    title=element.select(\"strong\")[0].text.strip(),\n",
    "                    # content=element.select(\".sa_text_lede\")[0].text.strip(),\n",
    "                    content=content_bs.text.strip(),\n",
    "                    image=content_bs.select(\"img\")[0][\"data-src\"].strip() if content_bs.select(\"img\") else DEFAULT_IMAGE_URL,\n",
    "                    url=element.select(\"a\")[0][\"href\"].strip(),\n",
    "                    pub_time=pub_time,\n",
    "                    section=section,\n",
    "                    press=element.select(\".sa_text_press\")[0].text.strip(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        sleep(0.5 + randint(0, 30))\n",
    "\n",
    "    news[section] = articles[:]\n",
    "    print(section)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save news data to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for section in sections.keys():\n",
    "    articles = news[section]\n",
    "    articles.insert(0, tuple(title for title in Article._fields))\n",
    "\n",
    "    with open(f\"./articles-{section}.csv\", 'w', encoding=\"utf8\") as f:\n",
    "        csv.writer(f).writerows(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load news data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_life: list[Article] = []\n",
    "\n",
    "with open(\"./articles-생활.csv\", 'r', encoding=\"utf8\") as f:\n",
    "    for i in csv.reader(f):\n",
    "        news_life.append(\n",
    "            Article(\n",
    "                title=i[0],\n",
    "                content=i[1],\n",
    "                url=i[2],\n",
    "                image=i[6],\n",
    "                pub_time=i[3],\n",
    "                section=i[4],\n",
    "                press=i[5]\n",
    "            )\n",
    "        )\n",
    "\n",
    "news_life.pop(0)\n",
    "news_life[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 뉴스 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_news = news_life[2]\n",
    "sample_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.get_uploaded_journals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = ApiWrapper()\n",
    "\n",
    "# for n in news:\n",
    "    # 언론사 등록 확인\n",
    "\n",
    "n = sample_news\n",
    "\n",
    "journal_id = api.upload_journal(n.press)\n",
    "tag_id = api.upload_tag(n.section, n.section)\n",
    "\n",
    "data = {\n",
    "    \"title\": n.title,\n",
    "    \"link\": n.url,\n",
    "    \"journalId\": journal_id,\n",
    "    \"publicationDate\": n.pub_time,\n",
    "    \"tagIds\": [tag_id]\n",
    "}\n",
    "\n",
    "response = api.send(\"/news\", auth=True, data=data)\n",
    "\n",
    "print(response.status_code)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.send(\"/news\", auth=True).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "press = list(set([news.press for news in news_life]))\n",
    "\n",
    "presses = {\n",
    "    i: press[i] for i in range(len(press))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for press_id in presses.keys():\n",
    "    print(press_id, presses[press_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_press_name_from_press_id(id: int):\n",
    "    for press_id in presses.keys():\n",
    "        if press_id == id:\n",
    "            return presses[press_id]\n",
    "\n",
    "\n",
    "def get_press_id_from_press_name(name: str):\n",
    "    for press_id in presses.keys():\n",
    "        if presses[press_id] == name:\n",
    "            return press_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = ApiWrapper().login()\n",
    "URL = ApiWrapper().URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for press_id in presses.keys():\n",
    "    response = requests.post(\n",
    "        URL + \"/journal\",\n",
    "\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "        },\n",
    "\n",
    "        data={\n",
    "            \"journalNm\": presses[press_id]\n",
    "            \"journalId\": press_id,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    URL + \"/news\",\n",
    "\n",
    "    headers={\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "    },\n",
    "\n",
    "    json={\n",
    "        \"title\": sample_news.title,\n",
    "        \"link\": sample_news.url,\n",
    "        # \"journalId\": get_press_id_from_press_name(sample_news.press),\n",
    "        \"journalId\": sample_news.press,\n",
    "        \"publicationDate\": sample_news.pub_time.split('+')[0],\n",
    "        \"tagIds\": [\n",
    "            6\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "if model is not None:\n",
    "    del model\n",
    "if tokenizer is not None:\n",
    "    del tokenizer\n",
    "\n",
    "model_id = 'MLP-KTLim/llama-3-Korean-Bllossom-8B-gguf-Q4_K_M'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = Llama(\n",
    "    model_path='/home/gpp/src/model/llama3-korean-bllossom-8b/llama-3-Korean-Bllossom-8B-Q4_K_M.gguf',\n",
    "    n_ctx=8192,\n",
    "    n_gpu_layers=-1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "def apply_prompt(instruction: str) -> str:\n",
    "    PROMPT = \\\n",
    "    \"\"\"\n",
    "    다음은 [뉴스 제목]과 [뉴스 본문]입니다.\n",
    "    요약에는 \"주제\"와 \"주요 내용\"이 포함되어야 합니다.\n",
    "    - \"problem\": 뉴스의 주요 문제를 설명하는 핵심 문장\n",
    "    - \"summerized\": 뉴스의 요약, 50자 이상의 세 문장\n",
    "    - \"keyword\": 뉴스의 핵심 키워드\n",
    "    다음은 예시입니다. keyword는 반드시 명사형으로 된 한 문장으로 작성해야 합니다.\n",
    "\n",
    "    {\n",
    "        \"problem\": \"기후 변화로 부산 지역 해수면 상승\",\n",
    "        \"summerized\": \"최근 부산 지역 해수면이 0.5cm 상승했다. 부산대학교 해양과학과 조교수는 이를 기후 변화로 인한 결과로 보았다. 환경부와 국토교통부는 내달 합동 조사단을 꾸려 해수면 상승 원인을 찾기로 했다.\",\n",
    "        \"keyword\": \"부산 지역 해수면 상승\"\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    generation_kwargs = {\n",
    "        \"max_tokens\":4096,\n",
    "        \"stop\":[\"<|eot_id|>\"],\n",
    "        \"top_p\":0.9,\n",
    "        \"temperature\":0.3,\n",
    "\n",
    "    }\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{PROMPT}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{instruction}\"}\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize = False,\n",
    "        add_generation_prompt=True,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    response = model(prompt, **generation_kwargs)\n",
    "    return response[\"choices\"][0][\"text\"]\n",
    "\n",
    "apply_prompt(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "news_summarized: list[SummerizedArticle] = []\n",
    "\n",
    "section = \"생활 분야\"\n",
    "\n",
    "# PROMPT = \\\n",
    "# f\"\"\"\n",
    "# 다음은 {section} 뉴스의 [뉴스 제목]과 [뉴스 본문]입니다.\n",
    "# 요약에는 \"주제\"와 \"주요 내용\"이 포함되어야 합니다.\n",
    "# 출력은 JSON 형식으로 해주세요. 각 키는 \"problem\", \"issue\", \"summerized\", \"keyword\"입니다.\n",
    "# - \"problem\": 뉴스의 주요 문제를 설명하는 문장\n",
    "# - \"summerized\": 뉴스의 요약, 50자 이상의 세 문장\n",
    "# - \"issue\": 뉴스의 핵심 문장을 포함하는 완결된 한 문장\n",
    "# - \"keyword\": 뉴스의 핵심을 집약하는 한 단어, 7어절 이하 명사형 문장\n",
    "\n",
    "# 출력은 JSON 형식으로 요청 드린 내용만 담아 주세요.\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"max_tokens\":4096,\n",
    "    \"stop\":[\"<|eot_id|>\"],\n",
    "    \"top_p\":0.9,\n",
    "    \"temperature\":0.3,\n",
    "\n",
    "}\n",
    "\n",
    "for article in tqdm(news_life):\n",
    "    title = article.title.replace(\"[\", \"<\").replace(\"]\", \">\")\n",
    "    content = article.content.replace(\"[\", \"<\").replace(\"]\", \">\")\n",
    "\n",
    "    instruction = f'''\n",
    "    [뉴스 제목]\\n\n",
    "    {title}\\n\n",
    "    [뉴스 본문]\\n\n",
    "    {content}\n",
    "    '''\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{PROMPT}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{instruction}\"}\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize = False,\n",
    "        add_generation_prompt=True,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    flag = True\n",
    "    \n",
    "    while flag:\n",
    "        flag = False\n",
    "        response = model(prompt, **generation_kwargs)\n",
    "        print(response[\"choices\"][0][\"text\"])\n",
    "\n",
    "        try:\n",
    "            response_json = json.loads(response[\"choices\"][0][\"text\"])\n",
    "\n",
    "            news_summarized.append(\n",
    "                SummerizedArticle(\n",
    "                    title=title,\n",
    "                    content=response_json['problem'],\n",
    "                    url=article.url,\n",
    "                    pub_time=article.pub_time,\n",
    "                    section=article.section,\n",
    "                    press=article.press,\n",
    "                    problem=response_json['problem'],\n",
    "                    issue=response_json['issue'],\n",
    "                    keyword=response_json['keyword'],\n",
    "                    tag=article.section\n",
    "                )\n",
    "            )\n",
    "        except:\n",
    "            flag = True\n",
    "            print(\"error!\\r\", end=\"\")\n",
    "            messages[1][\"content\"] = instruction + \"\\n출력은 JSON 형식이어야 합니다. 다시 시도하세요.\"\n",
    "            continue\n",
    "        \n",
    "\n",
    "    # print(response['choices'][0]['text'][len(prompt):])\n",
    "\n",
    "    # 요약 뉴스: 아티클, 뉴스 원문: 뉴스\n",
    "    # 키워드: LLM이 분류한 이슈 - 요약 뉴스에 들어감\n",
    "    # 태그: 원본 뉴스가 속한 카테고리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_life[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "section = \"생활 분야\"\n",
    "\n",
    "PROMPT = \\\n",
    "f\"\"\"\n",
    "다음은 {section} 뉴스의 [뉴스 제목]과 [뉴스 본문]입니다.\n",
    "이 뉴스는 어떤 연령대, 어떤 성별의 사람들이 가장 관심을 가질까요?\n",
    "\"\"\"\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"max_tokens\":4096,\n",
    "    \"stop\":[\"<|eot_id|>\"],\n",
    "    \"top_p\":0.9,\n",
    "    \"temperature\":0.3,\n",
    "\n",
    "}\n",
    "\n",
    "for article in tqdm([news_life[17]]):\n",
    "    title = article.title.replace(\"[\", \"<\").replace(\"]\", \">\")\n",
    "    content = article.content.replace(\"[\", \"<\").replace(\"]\", \">\")\n",
    "\n",
    "    instruction = \\\n",
    "    f'''\n",
    "    [뉴스 제목]\\n\n",
    "    {title}\\n\n",
    "    [뉴스 본문]\\n\n",
    "    {content}\n",
    "    '''\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{PROMPT}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{instruction}\"}\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize = False,\n",
    "        add_generation_prompt=True,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    response = model(prompt, **generation_kwargs)\n",
    "    print(response[\"choices\"][0][\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_summarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_life[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모듈 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 뉴스 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrapper.news_fetcher import NewsFetcher\n",
    "\n",
    "news = NewsFetcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_list = news.fetch_news(n_pages=5)\n",
    "news.save_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 뉴스 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrapper.api_wrapper import ApiWrapper\n",
    "\n",
    "api = ApiWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.upload_news(news.news[\"정치\"][1:])\n",
    "api.upload_news(news.news[\"사회\"][1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrapper.llm_wrapper import LLM\n",
    "from tqdm import tqdm\n",
    "\n",
    "from wrapper.news_fetcher import NewsFetcher\n",
    "from entity.entity import *\n",
    "\n",
    "\n",
    "news = NewsFetcher().load_csv()[\"사회\"]\n",
    "\n",
    "llm = LLM(n_ctx=8192, max_tokens=512)\n",
    "summerized: list[SummerizedNews] = []\n",
    "\n",
    "for i, target in tqdm(enumerate(news), total=len(news)):\n",
    "    llm.set_prompt(\n",
    "        f\"\"\"\n",
    "        다음 형식에 맞추어 핵심 키워드 중심으로의 세 문장으로 요약해 주세요.\n",
    "        이 뉴스는 무작위로 선택된 {target.tag} 분야의 뉴스입니다.\n",
    "        요약하신 자료는 텍스트 임베딩을 거쳐 클러스터링 작업에 사용될 겁니다.\n",
    "\n",
    "        1. 이 기사에서 다루는 핵심 사건\n",
    "        2. 사건의 배경과 관련된 맥락\n",
    "        3. 사건이 가지는 의미나 시사점, 중요성\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    content = llm.generate(\n",
    "        f\"\"\"\n",
    "        title: {target.title}\\n\n",
    "        content: {target.content}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    summerized.append(SummerizedNews(title=target.title, content=content, topics=\"\", id=1288+i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summerized[1].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summerized[5].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 클러스터링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 요약문 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from llama_cpp import Llama\n",
    "\n",
    "\n",
    "del llm\n",
    "\n",
    "MODEL_PATH = \"/home/gpp/src/model/llama3-korean-bllossom-8b/llama-3-Korean-Bllossom-8B-Q4_K_M.gguf\"\n",
    "MODEL_ID = \"MLP-KTLim/llama-3-Korean-Bllossom-8B-gguf-Q4_K_M\"\n",
    "\n",
    "model = Llama(\n",
    "    model_path=MODEL_PATH,\n",
    "    embedding=True,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for texts in tqdm(summerized):\n",
    "    embedding = model.embed(texts.content)\n",
    "    embeddings.append({texts.id: embedding})\n",
    "\n",
    "X = [embeddings[i][summerized[i].id] for i in range(len(summerized))]\n",
    "max_length = max([len(x) for x in X])\n",
    "\n",
    "# 패딩된 임베딩 생성\n",
    "padded_X = np.array([np.pad(x, ((0, max_length - len(x)), (0, 0)), 'constant') for x in X])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(padded_X.reshape(len(padded_X), -1))\n",
    "similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# X는 TF-IDF 벡터 또는 다른 임베딩 벡터\n",
    "similarity_matrix = cosine_similarity(padded_X.reshape(len(padded_X), -1))\n",
    "distance_matrix = 1 - similarity_matrix  # 코사인 거리\n",
    "\n",
    "# DBSCAN 클러스터링\n",
    "dbscan = DBSCAN(eps=0.735, min_samples=2, metric='precomputed')\n",
    "clusters = dbscan.fit_predict(distance_matrix)\n",
    "\n",
    "# 클러스터 결과\n",
    "for cluster_id in set(clusters):\n",
    "    if cluster_id != -1:  # -1은 노이즈\n",
    "        print(f\"Cluster {cluster_id}:\")\n",
    "        for i in np.where(clusters == cluster_id)[0]:\n",
    "            print(f\" - {news[i].title}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "n_clusters = 30  # 클러스터의 개수를 설정\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "# 3D 배열을 2D 배열로 변환\n",
    "n_samples = padded_X.shape[0]  # 샘플 수\n",
    "n_timesteps = padded_X.shape[1]  # 시간 스텝 수\n",
    "n_features = padded_X.shape[2]  # 피처 수\n",
    "\n",
    "# Reshape to (100, 240 * 4096)\n",
    "reshaped_X = padded_X.reshape(n_samples, n_timesteps * n_features)\n",
    "\n",
    "scaled = StandardScaler().fit_transform(reshaped_X)\n",
    "\n",
    "labels = kmeans.fit_predict(scaled)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in range(n_clusters):\n",
    "    for j in range(len(summerized)):\n",
    "        if labels[j] == cluster:\n",
    "            print(cluster, summerized[j].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summerized[0].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrapper.api_wrapper import ApiWrapper\n",
    "\n",
    "\n",
    "api = ApiWrapper()\n",
    "api.send(\"/article\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.send(\n",
    "    \"/article\",\n",
    "    method=\"POST\",\n",
    "    auth=True,\n",
    "    data={\n",
    "    \"title\": \"string\",\n",
    "    \"content\": \"string\",\n",
    "    \"publicationDate\": \"2024-10-20T08:42:38.012Z\",\n",
    "    \"newsIdxes\": [\n",
    "        0\n",
    "    ]\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
