{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof-of-Concept notepad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from collections import namedtuple\n",
    "\n",
    "Article = namedtuple(\"Article\", [\"title\", \"content\", \"url\", \"pub_time\", \"section\", \"press\"])\n",
    "SummerizedArticle = namedtuple(\"SummerizedArticle\", [\"title\", \"content\", \"url\", \"pub_time\", \"section\", \"press\", \"problem\", \"issue\", \"keyword\", \"tag\"])\n",
    "\n",
    "model = None\n",
    "tokenizer = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class LLM:\n",
    "    MODEL_ID = \"MLP-KTLim/llama-3-Korean-Bllossom-8B-gguf-Q4_K_M\"\n",
    "    MODEL_PATH = \"/home/gpp/src/model/llama3-korean-bllossom-8b/llama-3-Korean-Bllossom-8B-Q4_K_M.gguf\"\n",
    "\n",
    "    model: Llama | None = None\n",
    "    tokenizer: AutoTokenizer | None = None\n",
    "\n",
    "    prompt: str = \"\"\n",
    "\n",
    "    def __init__(self, verbose: bool=False, temperature: float=0.3, top_p: float=0.9, max_tokens: int=2048):\n",
    "        if LLM.model is None:\n",
    "            LLM.model = Llama(\n",
    "                model_path=LLM.MODEL_PATH,\n",
    "                n_ctx=8192,\n",
    "                n_gpu_layers=-1,\n",
    "                verbose=verbose\n",
    "            )\n",
    "        \n",
    "        if LLM.tokenizer is None:\n",
    "            LLM.tokenizer = AutoTokenizer.from_pretrained(LLM.MODEL_ID)\n",
    "\n",
    "        self.temperature = temperature\n",
    "        self.top_p = top_p\n",
    "        self.max_tokens = max_tokens\n",
    "        self.temperature = temperature\n",
    "        \n",
    "\n",
    "        \n",
    "        self.prompt: str = \"\"\n",
    "    \n",
    "    def __del__(self):\n",
    "        del LLM.model\n",
    "        del LLM.tokenizer\n",
    "\n",
    "        LLM.model = None\n",
    "        LLM.tokenizer = None\n",
    "\n",
    "    def set_prompt(self, prompt: str):\n",
    "        self.prompt = prompt\n",
    "        return\n",
    "    \n",
    "    def generate(self, instruction: str):\n",
    "        if len(self.prompt) == 0:\n",
    "            raise ValueError(\"prompt is not set.\")\n",
    "        \n",
    "        if len(instruction) == 0:\n",
    "            raise ValueError(\"instruction is not set.\")\n",
    "        \n",
    "        generation_kwargs = {\n",
    "            \"max_tokens\":self.max_tokens,\n",
    "            \"stop\":[\"<|eot_id|>\"],\n",
    "            \"top_p\":self.top_p,\n",
    "            \"temperature\":self.temperature,\n",
    "        }\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": f\"{self.prompt}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{instruction}\"}\n",
    "        ]\n",
    "\n",
    "        p = LLM.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        response = LLM.model(p, **generation_kwargs)\n",
    "        return response[\"choices\"][0][\"text\"]\n",
    "\n",
    "llm: LLM = LLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    We want to use the following press name as the ID for the database.\n",
    "    It must be in English and contain no special characters and spaces.\n",
    "    please give me converted journal IDs only.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def ss():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    \"https://alimexpress-api.rrkim.com/auth/eula\",\n",
    ")\n",
    "\n",
    "eula_ids: list[str] = []\n",
    "\n",
    "for i in response.json()[\"data\"]:\n",
    "    eula_ids.append(i[\"eulaId\"])\n",
    "\n",
    "eula_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    \"https://alimexpress-api.rrkim.com/auth/sign-up\",\n",
    "\n",
    "    headers={\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    },\n",
    "\n",
    "    json={\n",
    "        \"userId\": \"LLM_TEST@test.com\",\n",
    "        \"password\": \"LLM_TEST\",\n",
    "        \"userNm\": \"LLM_TEST\",\n",
    "        \"gender\": \"MALE\",\n",
    "        \"birthDate\": \"2001-08-16\",\n",
    "        \"interestTagIds\": [\n",
    "            \"test_tag\"\n",
    "        ],\n",
    "        \"agreedEulaIds\": eula_ids\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    URL + \"/auth/token\",\n",
    "\n",
    "    headers={\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    },\n",
    "\n",
    "    json=AUTH\n",
    ")\n",
    "\n",
    "TOKEN: str = response.json()[\"data\"][0][\"token\"]\n",
    "TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fetch news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOW: str = datetime.now(tz=timezone(timedelta(hours=9))).strftime(\"%Y%m%d%H%M\")\n",
    "header: dict = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36\"}\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import re\n",
    "\n",
    "sections = {\n",
    "    # \"politics\" : 100,\n",
    "    # \"economy\": 101,\n",
    "    \"social\": 102,\n",
    "    \"life\": 103,\n",
    "    # \"world\": 104,\n",
    "    # \"science\": 105 \n",
    "}\n",
    "\n",
    "news = {\n",
    "    section : []\n",
    "    for section in sections.keys()\n",
    "}\n",
    "\n",
    "for section in sections.keys():\n",
    "    articles: list[Article] = []\n",
    "\n",
    "    for page in range(2):\n",
    "        url = f\"https://news.naver.com/section/template/SECTION_ARTICLE_LIST?sid={sections[section]}&sid2=&cluid=&pageNo={page}&date=&next={NOW}\"\n",
    "        response = requests.get(url, headers=header)\n",
    "        bs = BeautifulSoup(json.loads(response.text)[\"renderedComponent\"][\"SECTION_ARTICLE_LIST\"], 'html')\n",
    "        sleep(0.5 + randint(0, 100) * 0.1)\n",
    "\n",
    "        for element in bs.findAll(\"li\"):\n",
    "            url: str = element.select(\"a\")[0][\"href\"].strip()\n",
    "            response = requests.get(url, headers=header)\n",
    "\n",
    "            pub_time: str = element.select(\".sa_text_datetime\")[0].text.strip()\n",
    "\n",
    "            if pub_time[-2:-1] == \"분전\": # \"xx분전\"\n",
    "                numbers = int(\"\".join(re.findall(r'\\d+', )))\n",
    "\n",
    "                timestamp_utc = datetime.now(timezone.utc) - timedelta(minutes=numbers)\n",
    "                kst_time = timestamp_utc.astimezone(timezone(timedelta(hours=9)))\n",
    "                pub_time = kst_time.isoformat()\n",
    "\n",
    "            articles.append(\n",
    "                Article(\n",
    "                    title=element.select(\"strong\")[0].text.strip(),\n",
    "                    # content=element.select(\".sa_text_lede\")[0].text.strip(),\n",
    "                    content=BeautifulSoup(response.text).select(\"#newsct_article\")[0].text.strip(),\n",
    "                    url=element.select(\"a\")[0][\"href\"].strip(),\n",
    "                    pub_time=element.select(\".sa_text_datetime\")[0].text.strip(),\n",
    "                    section=section,\n",
    "                    press=element.select(\".sa_text_press\")[0].text.strip()\n",
    "                )\n",
    "            )\n",
    "\n",
    "        sleep(0.5 + randint(0, 30))\n",
    "\n",
    "    news[section] = articles[:]\n",
    "    print(section)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save news data to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for section in sections.keys():\n",
    "    articles = news[section]\n",
    "    articles.insert(0, tuple(title for title in Article._fields))\n",
    "\n",
    "    with open(f\"./articles-{section}.csv\", 'w', encoding=\"utf8\") as f:\n",
    "        csv.writer(f).writerows(articles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load news data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_life: list[Article] = []\n",
    "\n",
    "with open(\"./articles-life.csv\", 'r', encoding=\"utf8\") as f:\n",
    "    for i in csv.reader(f):\n",
    "        news_life.append(\n",
    "            Article(\n",
    "                title=i[0],\n",
    "                content=i[1],\n",
    "                url=i[2],\n",
    "                pub_time=i[3],\n",
    "                section=i[4],\n",
    "                press=i[5]\n",
    "            )\n",
    "        )\n",
    "\n",
    "news_life.pop(0)\n",
    "news_life[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 뉴스 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_news = news_life[0]\n",
    "sample_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "press = set([news.press for news in news_life])\n",
    "\n",
    "presses = {\n",
    "    i: news_life[i].press for i in range(len(press))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for press_id in presses.keys():\n",
    "    print(press_id, presses[press_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    URL + \"/journal\",\n",
    "\n",
    "    headers={\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "    },\n",
    "\n",
    "    data='journalNm:\"tes\"\\njournalId:\"tet\"'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for press_id in presses.keys():\n",
    "    response = requests.post(\n",
    "        URL + \"/journal\",\n",
    "\n",
    "        headers={\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "        },\n",
    "\n",
    "        json={\n",
    "            \"journalNm\": press_id,\n",
    "            \"journalId\": presses[press_id]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    URL + \"/news\",\n",
    "\n",
    "    headers={\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "    },\n",
    "\n",
    "    json={\n",
    "        \"title\": sample_news.title,\n",
    "        \"link\": sample_news.url,\n",
    "        \"journalId\": \"\",\n",
    "        \"publicationDate\": sample_news.pub_time,\n",
    "        \"tagIds\": [\n",
    "            \"\"\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "if model is not None:\n",
    "    del model\n",
    "if tokenizer is not None:\n",
    "    del tokenizer\n",
    "\n",
    "model_id = 'MLP-KTLim/llama-3-Korean-Bllossom-8B-gguf-Q4_K_M'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = Llama(\n",
    "    model_path='/home/gpp/src/model/llama3-korean-bllossom-8b/llama-3-Korean-Bllossom-8B-Q4_K_M.gguf',\n",
    "    n_ctx=8192,\n",
    "    n_gpu_layers=-1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "def apply_prompt(instruction: str) -> str:\n",
    "    PROMPT = \\\n",
    "    \"\"\"\n",
    "    다음은 [뉴스 제목]과 [뉴스 본문]입니다.\n",
    "    요약에는 \"주제\"와 \"주요 내용\"이 포함되어야 합니다.\n",
    "    - \"problem\": 뉴스의 주요 문제를 설명하는 핵심 문장\n",
    "    - \"summerized\": 뉴스의 요약, 50자 이상의 세 문장\n",
    "    - \"keyword\": 뉴스의 핵심 키워드\n",
    "    다음은 예시입니다. keyword는 반드시 명사형으로 된 한 문장으로 작성해야 합니다.\n",
    "\n",
    "    {\n",
    "        \"problem\": \"기후 변화로 부산 지역 해수면 상승\",\n",
    "        \"summerized\": \"최근 부산 지역 해수면이 0.5cm 상승했다. 부산대학교 해양과학과 조교수는 이를 기후 변화로 인한 결과로 보았다. 환경부와 국토교통부는 내달 합동 조사단을 꾸려 해수면 상승 원인을 찾기로 했다.\",\n",
    "        \"keyword\": \"부산 지역 해수면 상승\"\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    generation_kwargs = {\n",
    "        \"max_tokens\":4096,\n",
    "        \"stop\":[\"<|eot_id|>\"],\n",
    "        \"top_p\":0.9,\n",
    "        \"temperature\":0.3,\n",
    "\n",
    "    }\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{PROMPT}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{instruction}\"}\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize = False,\n",
    "        add_generation_prompt=True,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    response = model(prompt, **generation_kwargs)\n",
    "    return response[\"choices\"][0][\"text\"]\n",
    "\n",
    "apply_prompt(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "news_summarized: list[SummerizedArticle] = []\n",
    "\n",
    "section = \"생활 분야\"\n",
    "\n",
    "# PROMPT = \\\n",
    "# f\"\"\"\n",
    "# 다음은 {section} 뉴스의 [뉴스 제목]과 [뉴스 본문]입니다.\n",
    "# 요약에는 \"주제\"와 \"주요 내용\"이 포함되어야 합니다.\n",
    "# 출력은 JSON 형식으로 해주세요. 각 키는 \"problem\", \"issue\", \"summerized\", \"keyword\"입니다.\n",
    "# - \"problem\": 뉴스의 주요 문제를 설명하는 문장\n",
    "# - \"summerized\": 뉴스의 요약, 50자 이상의 세 문장\n",
    "# - \"issue\": 뉴스의 핵심 문장을 포함하는 완결된 한 문장\n",
    "# - \"keyword\": 뉴스의 핵심을 집약하는 한 단어, 7어절 이하 명사형 문장\n",
    "\n",
    "# 출력은 JSON 형식으로 요청 드린 내용만 담아 주세요.\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"max_tokens\":4096,\n",
    "    \"stop\":[\"<|eot_id|>\"],\n",
    "    \"top_p\":0.9,\n",
    "    \"temperature\":0.3,\n",
    "\n",
    "}\n",
    "\n",
    "for article in tqdm(news_life):\n",
    "    title = article.title.replace(\"[\", \"<\").replace(\"]\", \">\")\n",
    "    content = article.content.replace(\"[\", \"<\").replace(\"]\", \">\")\n",
    "\n",
    "    instruction = f'''\n",
    "    [뉴스 제목]\\n\n",
    "    {title}\\n\n",
    "    [뉴스 본문]\\n\n",
    "    {content}\n",
    "    '''\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{PROMPT}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{instruction}\"}\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize = False,\n",
    "        add_generation_prompt=True,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    flag = True\n",
    "    \n",
    "    while flag:\n",
    "        flag = False\n",
    "        response = model(prompt, **generation_kwargs)\n",
    "        print(response[\"choices\"][0][\"text\"])\n",
    "\n",
    "        try:\n",
    "            response_json = json.loads(response[\"choices\"][0][\"text\"])\n",
    "\n",
    "            news_summarized.append(\n",
    "                SummerizedArticle(\n",
    "                    title=title,\n",
    "                    content=response_json['problem'],\n",
    "                    url=article.url,\n",
    "                    pub_time=article.pub_time,\n",
    "                    section=article.section,\n",
    "                    press=article.press,\n",
    "                    problem=response_json['problem'],\n",
    "                    issue=response_json['issue'],\n",
    "                    keyword=response_json['keyword'],\n",
    "                    tag=article.section\n",
    "                )\n",
    "            )\n",
    "        except:\n",
    "            flag = True\n",
    "            print(\"error!\\r\", end=\"\")\n",
    "            messages[1][\"content\"] = instruction + \"\\n출력은 JSON 형식이어야 합니다. 다시 시도하세요.\"\n",
    "            continue\n",
    "        \n",
    "\n",
    "    # print(response['choices'][0]['text'][len(prompt):])\n",
    "\n",
    "    # 요약 뉴스: 아티클, 뉴스 원문: 뉴스\n",
    "    # 키워드: LLM이 분류한 이슈 - 요약 뉴스에 들어감\n",
    "    # 태그: 원본 뉴스가 속한 카테고리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_life[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "section = \"생활 분야\"\n",
    "\n",
    "PROMPT = \\\n",
    "f\"\"\"\n",
    "다음은 {section} 뉴스의 [뉴스 제목]과 [뉴스 본문]입니다.\n",
    "이 뉴스는 어떤 연령대, 어떤 성별의 사람들이 가장 관심을 가질까요?\n",
    "\"\"\"\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"max_tokens\":4096,\n",
    "    \"stop\":[\"<|eot_id|>\"],\n",
    "    \"top_p\":0.9,\n",
    "    \"temperature\":0.3,\n",
    "\n",
    "}\n",
    "\n",
    "for article in tqdm([news_life[17]]):\n",
    "    title = article.title.replace(\"[\", \"<\").replace(\"]\", \">\")\n",
    "    content = article.content.replace(\"[\", \"<\").replace(\"]\", \">\")\n",
    "\n",
    "    instruction = \\\n",
    "    f'''\n",
    "    [뉴스 제목]\\n\n",
    "    {title}\\n\n",
    "    [뉴스 본문]\\n\n",
    "    {content}\n",
    "    '''\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{PROMPT}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{instruction}\"}\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize = False,\n",
    "        add_generation_prompt=True,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    response = model(prompt, **generation_kwargs)\n",
    "    print(response[\"choices\"][0][\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_summarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_life[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
